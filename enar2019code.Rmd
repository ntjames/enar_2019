---
title: "Operating Characteristics of Bayesian Joint Benefit-Risk Copula Models"
author: "Nathan T. James"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
#For code block want echo=TRUE if (knitr::is_html_output())
# echo=FALSE otherwise (e.g. echo = FALSE if (knitr::is_latex_output()))
knitr::opts_chunk$set(echo = knitr::is_html_output())
wd<-getwd()

# load packages
libs<-c("copula", "knitr", "magrittr", "ggplot2", "rstan", "plotly", "bayesplot", "ggExtra", "polycor")
invisible(lapply(libs, library, character.only = TRUE))
```


# Operating Characteristics of Bayesian Joint Benefit-Risk Copula Models

Simulations

1) binary - binary
2) continuous - continuous
3) continuous - binary (ex. 1 from Costa)
4) continuous - ordinal ??

For binary use logistic or probit?? 
use general log-likelihood function ??

params to vary (see *mod_simarray.R)
* correlation [in treatment group] (rho = 0.1, 0.35, 0.6) 
* sample size (n per arm = 25, 50, 150, 400) 
* true differences (3?)
* priors, other??

number of simulations under each scenario = 25? 50? 100? 200? 500? 

approx number of hours w/ 3x4x3 scenarios, 25 times each at ~30 secs per run (bb) or 120 sec per run (cb)
BB
(3*4*3*3*100*30)/3600 hrs for (3*4*3*3*100) sim ids
(3*4*3*3*25*30)/3600 hrs for (3*4*3*3*25) sim ids

CB models
(3*4*3**3*25*100)/3600



extension/future work - generate data from different copula models, use different models for fit

Outcomes (for each margin and for joint outcome??)

Bayesian power -
Probability of misleading evidence - 


-> how much does power (esp for low-info out - binary safety) improve when accounting for correlation between outcomes 

## Binary - Binary

### Simulate data

```{r bb-simdat, cache=TRUE}
# Simulate data
set.seed(6553)

# number of samples per arm
n <- 1e2

# placebo group
p_e1 <- 0.2 # prob effective
p_s1 <- 0.1 # prob AE
rho_1 <- 0.1 # tetrachoric correlation

# Normal copula

# function to get copula parameter given rho and p; see Costa section 3.1.2
#! getTheta <- function(rho,p){  (rho*sqrt(p*(1-p))) / dnorm(qnorm(p)) }

nc_p <- normalCopula(rho_1)

# Frank copula
if (0){
# function to get alpha estimate given rho --> check this in Meester!!
alp_fun <-function(alpha, r) {
  (1-alpha*exp(-alpha/2)-exp(-alpha))*(exp(-alpha/2)-1)^(-2) - r
}
alp_1 <- uniroot(alp_fun,c(-10,10), tol = 0.0001, r=rho_1)$root
fc_p <- frankCopula( alp_1 )
}

pbo_dist <- mvdc(nc_p, margins = c("binom", "binom"),
                paramMargins = list(list(size = 1, prob = p_e1), 
                                    list(size = 1, prob = p_s1)) )

pbo_samps <- rMvdc(n, pbo_dist)

if (0){ # check simulated values
mean(pbo_samps[,1]) # p_e1 
mean(pbo_samps[,2]) # p_s1
## cor(pbo_samps[,1], pbo_samps[,2], method = "spearman") 

polychor(pbo_samps[,1], pbo_samps[,2]) # rho_1
}

# treatment
p_e2 <- 0.5 # prob effective
p_s2 <- 0.4 # prob AE
rho_2 <- 0.6 # tetrachoric corr

# rho_2 <- 0.9 # this amount of tetrachoric correlation may be cause of sampling issue
# rho_2 <- 0.95

# normal copula
nc_t <- normalCopula(rho_2)

# Frank copula
#alp_2 <- uniroot(alp_fun,c(-10,10), tol = 0.0001, r=rho_2)$root
#fc_t <-  frankCopula( alp_2 )

trt_dist <- mvdc(nc_t, margins = c("binom", "binom"),
                paramMargins = list(list(size = 1, prob = p_e2), 
                                    list(size = 1, prob = p_s2)) )

trt_samps <- rMvdc(n, trt_dist)

if (0){ # check simulated values
mean(trt_samps[,1]) #p_e2
mean(trt_samps[,2]) #p_s2
##cor(trt_samps[,1],trt_samps[,2]) # rho_2 (Pearson corr)

polychor(trt_samps[,1], trt_samps[,2])
}

#combine placebo and treatment data
dat_bb <- rbind(pbo_samps,trt_samps) %>% cbind(sort(rep(c(0,1),n)),
                                            sort(rep(c(0,1),n),decreasing=TRUE),
                                            sort(rep(c(0,1),n))) %>% as.data.frame() 
names(dat_bb) <- c("efficacy","safety","treatment","trt1","trt2")


dat_bb_short<-plyr::count(dat_bb,vars=names(dat_bb))

# add meta-data with true values for n, p_e, p_s, rho

if (0){
dat_bb_lab <- dat_bb
dat_bb_lab %<>% mutate(treatment=factor(treatment, labels=c("placebo","active")),
                    efficacy=factor(efficacy, labels=c("not effective","effective")),
                   safety=factor(safety, labels=c("no AE","AE")))


# check crosstab by trt
table(dat_bb_lab$efficacy,dat_bb_lab$safety,dat_bb_lab$treatment)
}

```

### Individual marginal models

```{r bb-margmod, cache=TRUE}
# separate marginal models
mod_bb_e_code <- "
data {
  int<lower=0> N;
  matrix[N, 2] x;
  int<lower=0, upper=1> y_e[N];
}
parameters {
  //params for binary (efficacy) outcome
   vector[2] beta_e;
}
model {
  // priors
  beta_e ~ normal(0,1000); 

  // marginal for binary (efficacy) outcome
  y_e ~ bernoulli(Phi(x*beta_e)); 
  }
generated quantities {
  // transform to get p_e for placebo and treatment
  vector[2] p_e;
  p_e[1] = Phi(beta_e[1]);
  p_e[2] = Phi(beta_e[2]);
}
"

mod_bb_s_code <- "
data {
  int<lower=0> N;
  matrix[N, 2] x;
  int<lower=0, upper=1> y_s[N];
}
parameters {
  //params for binary (safety) outcome
   vector[2] beta_s;
}
model {
  // priors
  beta_s ~ normal(0,1000); 

  // marginal for binary (safety) outcome
  y_s ~ bernoulli(Phi(x*beta_s)); 
  }
generated quantities {
  // transform to get p_s for placebo and treatment
  vector[2] p_s;
  p_s[1] = Phi(beta_s[1]);
  p_s[2] = Phi(beta_s[2]);
}
"
```

```{r bb-setup-dat, cache=TRUE, warning=FALSE, include=FALSE}
## Run Stan models
# http://mc-stan.org/rstan/
rstan_options(auto_write = TRUE)

# MCMC parameters
options(mc.cores = parallel::detectCores())
n_chains <- 4
n_warmup <- 3500
n_iter <- n_warmup+2000

## marginal models assuming independence
# format data into list for stan
mod_data_bb <- list(N=nrow(dat_bb), x=dat_bb[,c("trt1","trt2")], 
                    y_e=dat_bb$efficacy, y_s=dat_bb$safety)


mod_data_bb_short <- list(N=nrow(dat_bb_short),
                          x=dat_bb_short[,c("trt1","trt2")],
                          y_e=dat_bb_short$efficacy,
                          y_s=dat_bb_short$safety,
                          freq=dat_bb_short$freq)
```

```{r bb-margfit, cache=TRUE, warning=FALSE, include=FALSE}
# fit efficacy marginal model
fit_bb_e <- stan(model_code = mod_bb_e_code, data=mod_data_bb, 
              iter=n_iter, warmup=n_warmup, chains=n_chains)

# fit safety marginal model
fit_bb_s <- stan(model_code = mod_bb_s_code, data=mod_data_bb, 
              iter=n_iter, warmup=n_warmup, chains=n_chains)

#! use rstanarm instead to avoid compilation?
```

#### Individual model MCMC diagnostics 

```{r bb-margsumm}
# efficacy model
# true params p_e1, p_e2 
summary(fit_bb_e)$summary

stan_plot(fit_bb_e, pars=c("p_e")) + 
  geom_point(aes(x=c(p_e1, p_e2), y=c(2,1)), color="blue", size=3)

stan_trace(fit_bb_e)


# safety model
# true params p_s1, p_s2 
summary(fit_bb_s)$summary

stan_plot(fit_bb_s, pars=c("p_s")) + 
  geom_point(aes(x=c(p_s1, p_s2), y=c(2,1)), color="blue", size=3)

stan_trace(fit_bb_s)
```


```{r bb-margdiag}
# efficacy model diagnostics
# see http://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html
posterior_fit_bb_e <- as.array(fit_bb_e)
np_fit_bb_e <- nuts_params(fit_bb_e)
lp_fit_bb_e <- log_posterior(fit_bb_e)
rhats_fit_bb_e <- rhat(fit_bb_e)
ratios_fit_bb_e <- neff_ratio(fit_bb_e)

## NUTS diagnostics
mcmc_parcoord(posterior_fit1a, np = np_fit_bb_e)
mcmc_pairs(posterior_fit_bb_e, np = np_fit_bb_e, pars = c("beta_e[1]","p_e[1]", "beta_e[2]","p_e[2]"))
mcmc_trace(posterior_fit_bb_e, pars = c("beta_e[1]", "beta_e[2]"), np = np_fit_bb_e) +
  xlab("Post-warmup iteration")
mcmc_nuts_divergence(np_fit_bb_e, lp_fit_bb_e)
mcmc_nuts_energy(np_fit_bb_e) # hists should look the same

## general MCMC diagnostics
# darker colors indicate poorer convergence diagnostics
mcmc_rhat(rhats_fit_bb_e) + yaxis_text(hjust = 1) 
mcmc_neff(ratios_fit_bb_e, size = 2) + yaxis_text(hjust = 1)

# safety model diagnostics
posterior_fit_bb_s <- as.array(fit_bb_s)
np_fit_bb_s <- nuts_params(fit_bb_s)
lp_fit_bb_s <- log_posterior(fit_bb_s)

```

### Joint copula model

```{r bb-jointmod, cache=TRUE}
# joint model
mod_bb_jnt_code <- "
functions {

// bivariate normal cdf (from Stan manual) - not as accurate as mvtnorm::pmvnorm
// see https://github.com/stan-dev/stan/issues/2356 and https://github.com/stan-dev/math/issues/962
real binormal_cdf(real z1, real z2, real rho){
  if (z1!=0 || z2 !=0){
    real denom = fabs(rho) < 1.0 ? sqrt((1+rho)*(1+rho)): not_a_number();
    real a1 = (z2/z1 - rho)/denom;
    real a2 = (z1/z2 - rho)/denom;
    real product = z1*z2;
    real delt = product < 0 || (product==0 && (z1+z2)<0);
  return 0.5*(Phi(z1)+Phi(z2)-delt)-owens_t(z1,a1)-owens_t(z2,a2);
  }
return 0.25 + asin(rho)/(2*pi());
}

// bivariate normal copula distribution function 
// see https://discourse.mc-stan.org/t/gaussian-copula-for-discrete-marginals/691/16
// also see STAN manual multivariate outcomes 
real pCop_norm(real u1, real u2, real theta){
  if (u1==0 || u2==0){ // grounded
    return 0;
  }
  else if (u1==1){ // uniform margin
    return u2;
  }
  else if (u2==1){ // uniform margin
    return u1;
  } else {
    return binormal_cdf(inv_Phi(u1), inv_Phi(u2), theta);
  }
}

// copula likelihood for 2 binary margins
real bi_cop_lp(int y1, real p1, int y2, real p2, real theta) {

  // pseudo-obs from bernoulli cdf (for either probit or logistic <- check this!!) 
  real U1 = bernoulli_cdf(y1, p1); 
  real U1_prime = bernoulli_cdf(y1-1, p1);
  real U2 = bernoulli_cdf(y2, p2); 
  real U2_prime = bernoulli_cdf(y2-1, p2);

  // likelihood for joint dist. using differences
  real cP0 = pCop_norm(U1, U2, theta) -
            pCop_norm(U1_prime, U2, theta) -
            pCop_norm(U1, U2_prime, theta) +
            pCop_norm(U1_prime, U2_prime, theta);

  // put lower bound on cP to avoid log(0)
  real cP = cP0 < 1e-300 ? 1e-300: cP0;

  // log-likelihood
  return log(cP);
}


}
data {
  int<lower=0> N;
  matrix[N, 2] x;
  int<lower=0, upper=1> y_e[N];
  int<lower=0, upper=1> y_s[N];
}
parameters {
  // params for binary (efficacy) outcome
  vector[2] beta_e;

  //params for binary (safety) outcome
  vector[2] beta_s;

  // copula dependence param
  vector<lower=-1, upper=1>[2] omega;  
}
transformed parameters {
  //vector[N] eta_e;
  //eta_e = x*beta_e;
}
model {
  vector[N] pr_e;
  vector[N] pr_s;
  vector[N] theta;

  // priors
  beta_e ~ normal(0,1000);
  beta_s ~ normal(0,1000); 
  omega ~ uniform(-1,1); 

  // marginal probit for binary (efficacy) outcome
    pr_e = Phi(x*beta_e);

  // marginal probit for binary (safety) outcome
    pr_s = Phi(x*beta_s);

  // copula dependence model
    theta = x*omega;

  // build log-likelihood
  //for(i in 1:N){
  // target += bi_cop_lp(y_e[i], pr_e[i], y_s[i], pr_s[i], theta[i]);
  //}

  {
  vector[N] loglik;  // vectorize summation
  for (i in 1:N)
    loglik[i] = bi_cop_lp(y_e[i], pr_e[i], y_s[i], pr_s[i], theta[i]);
  target += sum(loglik);
  }

}
generated quantities {
  vector[2] p_e;
  vector[2] p_s;

  p_e = Phi(beta_e);
  //p_e[1] = Phi(beta_e[1]);
  //p_e[2] = Phi(beta_e[2]);
  
  p_s = Phi(beta_s);
  //p_s[1] = Phi(beta_s[1]);
  //p_s[2] = Phi(beta_s[2]);
}
"
```

try improving efficiency see STAN user's guide v2.18 sec 23 pdf p 245 (also part II programming techniques pdf p 181) -  use counts of 8 groups (4 combs of y in pbo & trt) - calc loglik for each and multiply by number in group
```{r bb-jointmod2, cache=TRUE}
# joint model
mod_bb_jnt_code2 <- "
functions {

// bivariate normal cdf (from Stan manual) - not as accurate as mvtnorm::pmvnorm
// see https://github.com/stan-dev/stan/issues/2356 and https://github.com/stan-dev/math/issues/962
real binormal_cdf(real z1, real z2, real rho){
  if (z1!=0 || z2 !=0){
    real denom = fabs(rho) < 1.0 ? sqrt((1+rho)*(1+rho)): not_a_number();
    real a1 = (z2/z1 - rho)/denom;
    real a2 = (z1/z2 - rho)/denom;
    real product = z1*z2;
    real delt = product < 0 || (product==0 && (z1+z2)<0);
  return 0.5*(Phi(z1)+Phi(z2)-delt)-owens_t(z1,a1)-owens_t(z2,a2);
  }
return 0.25 + asin(rho)/(2*pi());
}

// bivariate normal copula distribution function 
// see https://discourse.mc-stan.org/t/gaussian-copula-for-discrete-marginals/691/16
// also see STAN manual multivariate outcomes
real pCop_norm(real u1, real u2, real theta){
  if (u1==0 || u2==0){ // grounded
    return 0;
  }
  else if (u1==1){ // uniform margin
    return u2;
  }
  else if (u2==1){ // uniform margin
    return u1;
  } else {
    return binormal_cdf(inv_Phi(u1), inv_Phi(u2), theta);
  }
}

// copula likelihood for 2 binary margins
real bi_cop_lp(int y1, real p1, int y2, real p2, real theta) {

  // pseudo-obs (should work for either probit or logistic, check this!!) 
  // bernoulli dist (either 1-p or 1??)
  real U1 = bernoulli_cdf(y1, p1); 
  real U1_prime = bernoulli_cdf(y1-1, p1);
  real U2 = bernoulli_cdf(y2, p2); 
  real U2_prime = bernoulli_cdf(y2-1, p2);

  // likelihood for joint dist. using differences
  real cP0 = pCop_norm(U1, U2, theta) -
            pCop_norm(U1_prime, U2, theta) -
            pCop_norm(U1, U2_prime, theta) +
            pCop_norm(U1_prime, U2_prime, theta);

  // put lower bound on cP to avoid log(0)
  real cP = cP0 < 1e-200 ? 1e-200: cP0;

  // log-likelihood
  return log(cP);
}


}
data {
  int<lower=1> N;
  matrix[N, 2] x;
  int<lower=0, upper=1> y_e[N];
  int<lower=0, upper=1> y_s[N];
  int<lower=0> freq[N];
}
parameters {
  // params for binary (efficacy) outcome
  vector[2] beta_e;

  //params for binary (safety) outcome
  vector[2] beta_s;

  // copula dependence param
  vector<lower=-1, upper=1>[2] omega;  
}
transformed parameters {
  //vector[N] eta_e;
  //eta_e = x*beta_e;
}
model {
  vector[N] pr_e;
  vector[N] pr_s;
  vector[N] theta;

  // priors
  beta_e ~ normal(0,1000);
  beta_s ~ normal(0,1000); 
  omega ~ uniform(-1,1); 

  // marginal probit for binary (efficacy) outcome
    pr_e = Phi(x*beta_e);
    //pr_e = Phi(beta_e[1]*x[1]+beta_e[2]*x[2]);

  // marginal probit for binary (safety) outcome
    pr_s = Phi(x*beta_s);
  //pr_s = Phi(beta_s[1]*x[1]+beta_s[2]*x[2]);

  // copula dependence model
    theta = x*omega;
  //theta = omega[1]*x[1]+omega[2]*x[2];

  // build log-likelihood
  {
  vector[N] loglik;  // vectorize summation
  for (i in 1:N)
    loglik[i] = freq[i]*bi_cop_lp(y_e[i], pr_e[i], y_s[i], pr_s[i], theta[i]);
  target += sum(loglik);
  }

}
generated quantities {
  vector[2] p_e;
  vector[2] p_s;

  p_e[1] = Phi(beta_e[1]);
  p_e[2] = Phi(beta_e[2]);

  p_s[1] = Phi(beta_s[1]);
  p_s[2] = Phi(beta_s[2]);
}
"
```

Troubleshoot errors

```{r, eval=FALSE}

library(mvtnorm)
expose_stan_functions(stanc(model_code = mod_bb_jnt_code))

#binormal_cdf(real z1, real z2, real rho)

binormal_cdf(0.3, -0.5, 0.2)
pmvnorm(upper=c(0.3, -0.5), corr=matrix(c(1,0.2,0.2,1), ncol=2))[[1]]

binormal_cdf(1.2, 1.2, 0.2)
pmvnorm(upper=c(1.2, 1.2), corr=matrix(c(1,0.2,0.2,1), ncol=2))[[1]]


#pCop_norm(real u1, real u2, real theta)
thet <- 0.5
nc<-normalCopula(thet)

pCopula(c(0.2, 0.7), nc)
pCop_norm(0.2, 0.7, thet)

pCopula(c(0.1, 0.9), nc)
pCop_norm(0.1, 0.9, thet)

pCopula(c(0.5, 0.5), nc)
pCop_norm(0.5, 0.5, thet)

pCopula(c(0.45, 0.5), nc)
pCop_norm(0.45, 0.5, thet)


# initializaton
y1 <- 1
y2 <- 0
p1 <- 0.2
p2 <- 0.5

U1 = pbinom(y1, 1, p1) 
U1_prime = pbinom(y1-1, 1, p1)
U2 = pbinom(y2, 1, p2) 
U2_prime = pbinom(y2-1, 1, p2)

if (0){
# if U is 0, Z is -Inf
Z1 = qnorm(U1) 
Z1_prime = qnorm(U1_prime)
Z2 = qnorm(U2)
Z2_prime = qnorm(U2_prime)

binormal_cdf(Z1, Z2, theta)-
binormal_cdf(Z1_prime, Z2, theta)-
binormal_cdf(Z1, Z2_prime, theta) +
binormal_cdf(Z1_prime, Z2_prime, theta)

# likelihood for joint dist. using differences
cP = pCop_norm(U1, U2, theta) -
            pCop_norm(U1_prime, U2, theta) -
            pCop_norm(U1, U2_prime, theta) +
            pCop_norm(U1_prime, U2_prime, theta)
}

pCopula(c(U1,U2),nc) -
pCopula(c(U1_prime,U2),nc) -
pCopula(c(U1,U2_prime),nc) +
pCopula(c(U1_prime,U2_prime),nc)

#bi_cop_lp(int y1, real p1, int y2, real p2, real theta)

exp(bi_cop_lp(y1, p1, y2, p2, thet))
```


Try multivariate probit model 
should match above, see STAN user's guide v2.18 sec 2.15 pdf p 42; not really working so far
can also try https://gist.github.com/khakieconomics/473bbcddf07e463b6b7cae8fa50bd53d
and see https://stackoverflow.com/questions/36044754/stan-copula-on-observed-variable-and-latent-variable
```{r bb-jointmod3, eval=FALSE, cache=TRUE}
# joint model
mod_bb_jnt_code3 <- "
functions {

// function to sum 2d array
int sum2d(int[,] a){
  int s=0;
  for (i in 1:size(a))
    s += sum(a[i]);
  return s;
}

}
data {
  // int<lower=0> N;
  // matrix[N, 2] x;
  // int<lower=0, upper=1> y_e[N];
  // int<lower=0, upper=1> y_s[N];

  int<lower=1> K; // number of covars
  int<lower=1> D; // dimensions of outcome (D=2 in this case)
  int<lower=0> N; // sample size
  int<lower=0, upper=1> y[N,D]; // N x D matrix of outcomes
  vector[K] x[N]; // covar vectors
}
transformed data {

  // sort data array y into positive and negative components

  int<lower=0> N_pos; // number of true (1) obs. in y
  int<lower=1, upper=N> n_pos[sum2d(y)];
  int<lower=1, upper=2> d_pos[size(n_pos)];

  int<lower=0> N_neg; // number of false (0) obs. in y
  int<lower=1, upper=N> n_neg[(N*D)-size(n_pos)];
  int<lower=1, upper=D> d_neg[size(n_neg)];

  N_pos = size(n_pos); 
  N_neg = size(n_neg); 
  {
    int i;
    int j;
    i = 1;
    j = 1;
    for (n in 1:N) {
      for (d in 1:D) {
        if (y[n,d]==1) {
          n_pos[i] = n;
          d_pos[i] = d;
          i += 1;
        } else {
          n_neg[j] = n;
          d_neg[j] = d;
          j += 1;
        }
      }
    }
  }

}
parameters {
  // params for binary (efficacy) outcome
  //vector[2] beta_e;

  //params for binary (safety) outcome
  //vector[2] beta_s;

  // copula dependence param
  //vector<lower=-1, upper=1>[2] omega;

  matrix[D, K] beta; // regression coefficients
  matrix[D, K] omega; // correlation model coefficients - should this be vector? or first dim 1
  cholesky_factor_corr[D] L_Omega; // cholesky of corr matrix
  vector<lower=0>[N_pos] z_pos; // pos. component of latent z
  vector<lower=0>[N_neg] z_neg; // neg. component of latent z

}
transformed parameters {
  vector[D] z[N]; // latent real value z
  for (n in 1:N_pos)
    z[n_pos[n],d_pos[n]] = z_pos[n];
  for (n in 1:N_neg)    
    z[n_neg[n],d_neg[n]] = z_neg[n];
}
model {
  //vector[N] theta; //!old

  // priors
  L_Omega ~ lkj_corr_cholesky(4); // !! make dependent on covars
  to_vector(beta) ~ normal(0,1000); // sd = 5 in STAN example

  // copula dependence model
  //theta = x*omega; //!old

  {
    vector[D] beta_x[N];
    vector[D] omega_x[N];
    // what is dim of this, need sep L_sigma for each n in 1:N
    matrix[D, D] L_sigma[N]; //! add 
    for (n in 1:N){
      beta_x[n] = beta * x[n]; //marginal regression vector[D=2] = matrix[D=2,K=2]* x[K=2]
      omega_x[n] = omega * x[n]; //dependence regression 
// want vector[D=2] = matrix[D=2,K=2]* x[K=2]
      L_sigma[n] = diag_pre_multiply(omega_x[n], L_Omega); //! add and switch lines below, [DxD] times DxD = DxD
      //target += multi_normal_cholesky_lpdf(z[n] | beta_x[n], L_Omega);
      target += multi_normal_cholesky_lpdf(z[n] | beta_x[n], L_sigma[n]);
    }
    //z ~ multi_normal_cholesky(beta_x, omega_x);
  }

  //vector[N] pr_e;
  //vector[N] pr_s;
  //vector[N] theta;

  // priors
  //beta_e ~ normal(0,1000);
  //beta_s ~ normal(0,1000); 
  //omega ~ uniform(-1,1); 

  // marginal probit for binary (efficacy) outcome
    //pr_e = Phi(x*beta_e);

  // marginal probit for binary (safety) outcome
    //pr_s = Phi(x*beta_s);

  // copula dependence model
    //theta = x*omega;

  // build log-likelihood
  //{
  //vector[N] loglik;  // vectorize summation
  //for (i in 1:N)
    //loglik[i] = bi_cop_lp(y_e[i], pr_e[i], y_s[i], pr_s[i], theta[i]);
  //target += sum(loglik);
  //}

}
generated quantities {
  row_vector[2] p_e;
  row_vector[2] p_s;
  // corr_matrix[D] Omega;

  p_e = Phi(beta[1]);
  //p_e = Phi(beta_e);

  p_s = Phi(beta[2]);
  //p_s = Phi(beta_s);
  
  // Omega = multiply_lower_tri_self_transpose(L_Omega);
}
"
```

fit multivar probit regression
```{r}
#  int<lower=1> K; // number of covars
#  int<lower=1> D; // dimensions of outcome (D=2 in this case)
#  int<lower=0> N; // sample size
#  int<lower=0, upper=1> y[N,D]; // N x D matrix of outcomes
#  vector[K] x[N]; // covar vectors

# data reformatted for this model
mod_data_bb3 <- list(K = 2, D = 2, N=nrow(dat_bb),
                     y = dat_bb[,c("efficacy","safety")],
                     x = dat_bb[,c("trt1","trt2")])

#initalize margins at jittered MLE estimate??
init_list0_3 <-  list(beta=rbind(mle_bb_e$coefficients,mle_bb_s$coefficients))
init_list_3 <- lapply(1:n_chains, function(x) lapply(init_list0_3 ,jitter, amount=2))

bb_fit3 <- stan(model_code = mod_bb_jnt_code3, data=mod_data_bb3, seed=789335,
             iter=n_iter, chains=n_chains, warmup=n_warmup,
             init=init_list_3, control = list(adapt_delta = 0.9))

```


try MV probit with brms
```{r, eval=FALSE}
library(brms)

# try with brms
#new_dat <- data.frame(subject=1:nrow(dat_bb),y=dat_bb$efficacy,x=dat_bb$treatment)

dat_bb$id <- 1:nrow(dat_bb)

brm_fit<-brm(formula = efficacy ~ treatment + (1 | gr(id, by = treatment)), data=dat_bb, family=bernoulli(link = "probit"))

brm_fit

stancode(brm_fit)


vignette("brms_multivariate")

# corr between outcomes not modeled
brm_fit2 <- brm(mvbind(efficacy,safety) ~ 0 + trt1 + trt2, data=dat_bb, family=bernoulli(link = "probit"))

stancode(brm_fit2)

# model corr between outcomes - don't think you can do this in brms except for gaussian and student-t 
brm_fit3 <- brm(mvbind(efficacy,safety) ~ 0 + trt1 + trt2, data=dat_bb, family=bernoulli(link = "probit"))

# fit incorrect 'gaussian' link 
brm_fit4 <- brm(bf(efficacy~0 + trt1 + trt2) +bf(safety ~ 0 + trt1 + trt2) + set_rescor(TRUE), data=dat_bb)

stancode(brm_fit4)

#different corr between outcomes by trt group




```


try MV probit with rstanarm
```{r}

library(rstanarm)
dat_bb$id <- 1:nrow(dat_bb)


rsa_fit2 <- stan_mvmer(
        formula = list(
          efficacy ~ treatment + (1|treatment), 
          safety ~ treatment + (1|treatment)),
        data = dat_bb, 
        family = list(binomial(link="probit"), binomial(link="probit")),
        # this next line is only to keep the example small in size!
        chains = 2, cores = 2, seed = 12345, iter = 1000)

plot(rsa_fit2)



rsa_fit3 <- stan_mvmer(
        formula = list(
          efficacy ~ trt1 + trt2 - 1 + (1|treatment), 
          safety ~ trt1 + trt2 - 1 + (1|treatment)),
        data = dat_bb, 
        family = list(binomial(link="probit"), binomial(link="probit")),
        # this next line is only to keep the example small in size!
        chains = n_chains, cores = n_chains, seed = 12345, iter = n_iter, warmup = n_warmup)

summary(rsa_fit3)
```




Fit joint binary-binary model

```{r bb-jointfit}
## joint copula model
# efficacy marginal model MLE for initialization
mle_bb_e<-glm(efficacy~trt1+trt2-1,data=dat_bb,family=binomial(link="probit"))

# safety marginal model MLE for initialization
mle_bb_s<-glm(safety~trt1+trt2-1,data=dat_bb,family=binomial(link="probit"))

#initalize margins at jittered MLE estimate??
init_list0 <-  list(beta_e=mle_bb_e$coefficients, beta_s=mle_bb_s$coefficients)
init_list <- lapply(1:n_chains, function(x) lapply(init_list0 ,jitter, amount=2))

# fit joint model
#system.time()
# around 90 sec with compilation, around 45 sec after compilation
# how to use compiled model with new data on ACCRE
if(0){
bb_fit <- stan(model_code = mod_bb_jnt_code, data=mod_data_bb, seed=789335,
             iter=n_iter, chains=n_chains, warmup=n_warmup,
             init=init_list, control = list(adapt_delta = 0.95))
}

# this model is much faster
bb_fit2 <- stan(model_code = mod_bb_jnt_code2, data=mod_data_bb_short, seed=789335,
             iter=n_iter, chains=n_chains, warmup=n_warmup,
             init=init_list, control = list(adapt_delta = 0.95))
```


#### Joint model MCMC diagnostics

```{r}

p_pars <- c("p_e[1]","p_e[2]","p_s[1]","p_s[2]")
beta_pars <- c("beta_e[1]","beta_e[2]","beta_s[1]","beta_s[2]")
omega_pars <- c("omega[1]","omega[2]")

summary(bb_fit)$summary

stan_plot(bb_fit, pars=p_pars) + 
  geom_point(aes(x=c(p_e1, p_e2, p_s1, p_s2), y=c(4,3,2,1)), color="blue", size=3)

stan_plot(bb_fit, pars=omega_pars) + 
  geom_point(aes(x=c(rho_1,rho_2), y=c(2,1)), color="blue", size=3)

stan_trace(bb_fit, pars=p_pars)
stan_trace(bb_fit, pars=omega_pars)

# diagnostic
posterior_bb_fit <- as.array(bb_fit)
np_bb_fit <- nuts_params(bb_fit)
lp_bb_fit <- log_posterior(bb_fit)
rhats_bb_fit <- rhat(bb_fit)
ratios_bb_fit <- neff_ratio(bb_fit)

## NUTS diagnostics
mcmc_parcoord(posterior_bb_fit, np = np_bb_fit)

mcmc_pairs(posterior_bb_fit, np = np_bb_fit, pars = p_pars)
mcmc_pairs(posterior_bb_fit, np = np_bb_fit, pars = beta_pars)

mcmc_trace(posterior_bb_fit, np = np_bb_fit, pars = p_pars) +
  xlab("Post-warmup iteration")
mcmc_nuts_divergence(np_bb_fit, lp_bb_fit)
mcmc_nuts_energy(np_bb_fit) # hists should look the same

## general MCMC diagnostics
# darker colors indicate worse convergence diagnostics
mcmc_rhat(rhats_bb_fit) + yaxis_text(hjust = 1) 
mcmc_neff(ratios_bb_fit, size = 2) + yaxis_text(hjust = 1)

```

using summarized data
```{r}

p_pars <- c("p_e[1]","p_e[2]","p_s[1]","p_s[2]")
beta_pars <- c("beta_e[1]","beta_e[2]","beta_s[1]","beta_s[2]")
omega_pars <- c("omega[1]","omega[2]")

summary(bb_fit2)$summary

stan_plot(bb_fit2, pars=p_pars) + 
  geom_point(aes(x=c(p_e1, p_e2, p_s1, p_s2), y=c(4,3,2,1)), color="blue", size=3)

stan_plot(bb_fit2, pars=omega_pars) + 
  geom_point(aes(x=c(rho_1,rho_2), y=c(2,1)), color="blue", size=3)

stan_trace(bb_fit2, pars=p_pars)
stan_trace(bb_fit2, pars=omega_pars)

# diagnostic
posterior_bb_fit2 <- as.array(bb_fit2)
np_bb_fit2 <- nuts_params(bb_fit2)
lp_bb_fit2 <- log_posterior(bb_fit2)
rhats_bb_fit2 <- rhat(bb_fit2)
ratios_bb_fit2 <- neff_ratio(bb_fit2)

## NUTS diagnostics
mcmc_parcoord(posterior_bb_fit2, np = np_bb_fit2)

mcmc_pairs(posterior_bb_fit2, np = np_bb_fit2, pars = p_pars)
mcmc_pairs(posterior_bb_fit2, np = np_bb_fit2, pars = beta_pars)

mcmc_trace(posterior_bb_fit2, np = np_bb_fit2, pars = p_pars) +
  xlab("Post-warmup iteration")
mcmc_nuts_divergence(np_bb_fit2, lp_bb_fit2)
mcmc_nuts_energy(np_bb_fit2) # hists should look the same

## general MCMC diagnostics
# darker colors indicate worse convergence diagnostics
mcmc_rhat(rhats_bb_fit2) + yaxis_text(hjust = 1) 
mcmc_neff(ratios_bb_fit2, size = 2) + yaxis_text(hjust = 1)

```

### Compare individual and copula models

```{r}
#! make function that loops over all sim data

wdir<-file.path("/home/nathan/Dropbox/njames/school/PhD/misc/conferences/ENAR2019/code")
load(file.path(wdir,"sims","bb_sim_1.RData"))

# use tidyverse tibbles or broom?
if (0){
library(tidyverse)
bb_1 <- summary(bb_fit,pars=c("p_e", "p_s"))$summary
bb_2 <- summary(fit_bb_e, pars=c("p_e"))$summary
bb_3 <- summary(fit_bb_s, pars=c("p_s"))$summary

as.tibble(bb_1) %>% mutate(mod="full")
as.tibble(rbind(bb_2,bb_3)) 


library(broom)
bb_1 <- tidy(fit_bb_jnt, pars=c("p_e", "p_s"), estimate.methd="median", conf.int = T, conf.method="HPDinterval") %>% mutate(mod="cop")

bb_2 <- tidy(fit_bb_e, pars=c("p_e"), estimate.methd="median", conf.int = T, conf.method="HPDinterval") %>% mutate(mod="sep")

bb_3 <- tidy(fit_bb_s, pars=c("p_s"), estimate.methd="median", conf.int = T, conf.method="HPDinterval") %>% mutate(mod="sep")

bb<-rbind(bb_1,bb_2,bb_3)
}


library(ggstance)
ggplot(data=bb,aes(x=estimate, y=term, group=mod)) + geom_point(aes(shape=mod), position=position_dodgev(height=0.2))

ggplot(data=bb,aes(x=estimate, xmin=conf.low, xmax=conf.high, y=term, color=mod)) + 
  geom_point(aes(shape=mod), position=position_dodgev(height=0.4), alpha=0.4) +
  geom_linerangeh(position=position_dodgev(height=0.4), alpha=0.4) +
  geom_point(data=data.frame(x=c(p_e1, p_e2, p_s1, p_s2),y=1:4), aes(x=x,y=y),
             color="blue", size=2, inherit.aes = FALSE)


# make fake bb2
bb2 <- bb
bb2 %<>% mutate_if(is.double, jitter, amount=0.1)
bb %<>% mutate(sim=1)
bb2 %<>% mutate(sim=2)

simdat<-rbind(bb,bb2)

ggplot(data=simdat,aes(x=estimate, xmin=conf.low, xmax=conf.high, y=term, color=mod)) + 
  geom_point(aes(shape=mod), position=position_dodgev(height=0.4), alpha=0.4) +
  geom_linerangeh(position=position_dodgev(height=0.4), alpha=0.4) +
  geom_point(data=data.frame(x=c(p_e1, p_e2, p_s1, p_s2),y=1:4), aes(x=x,y=y),
             color="blue", size=2, inherit.aes = FALSE)

if(0){
stan_plot(bb_fit, pars=c("p_e")) + 
  geom_point(aes(x=c(p_e1, p_e2), y=c(2,1)), color="blue", size=3)

stan_plot(fit_bb_e, pars=c("p_e")) + 
  geom_point(aes(x=c(p_e1, p_e2), y=c(2,1)), color="blue", size=3)

stan_plot(bb_fit, pars=c("p_s")) + 
  geom_point(aes(x=c(p_s1, p_s2), y=c(2,1)), color="blue", size=3)

stan_plot(fit_bb_s, pars=c("p_s")) + 
  geom_point(aes(x=c(p_s1, p_s2), y=c(2,1)), color="blue", size=3)
}

```

## Continuous - Continuous


## Continuous - Binary

### Simulate data

```{r br-a, cache=TRUE}
# Simulate data
set.seed(4283)

# function to get copula parameter given rho and p; see Costa section 3.1.2
getTheta <- function(rho,p){  (rho*sqrt(p*(1-p))) / dnorm(qnorm(p)) }

# number of samples per arm
n <- 100

# placebo group
mu_1 <- -150
sigma2_1 <- 100^2
p_1 <- 0.1  
rho_1 <- 0.1

# normal copula
nc_p <- normalCopula( getTheta(rho=rho_1, p=p_1)  )

pbo_dist <- mvdc(nc_p, margins = c("norm","binom"),
                paramMargins = list(list(mean = mu_1, sd = sqrt(sigma2_1)), 
                                    list(size = 1, prob = p_1)) )

pbo_samps<-rMvdc(n, pbo_dist)

if (0){ # check simulated values
mean(pbo_samps[,1]) # mu_1
sd(pbo_samps[,1]) # sigma_1
mean(pbo_samps[,2]) #p_1
cor(pbo_samps[,1],pbo_samps[,2]) # rho_1 (Pearson corr)
}

# treatment
mu_2 <- -50
sigma2_2 <- 100^2
p_2 <- 0.4
rho_2 <- 0.6

# normal copula
nc_t <- normalCopula( getTheta(rho=rho_2, p=p_2)  )

trt_dist <- mvdc(nc_t, margins = c("norm","binom"),
                paramMargins = list(list(mean = mu_2, sd = sqrt(sigma2_2)), 
                                    list(size = 1, prob = p_2)) )

trt_samps <- rMvdc(n, trt_dist)

if (0){ # check simulated values
mean(trt_samps[,1]) # mu_2
sd(trt_samps[,1]) # sigma_2
mean(trt_samps[,2]) #p_2
cor(trt_samps[,1],trt_samps[,2]) # rho_2 (Pearson corr)
}

#combine placebo and treatment data
dat <- rbind(pbo_samps,trt_samps) %>% cbind(sort(rep(c(0,1),n)),
                                            sort(rep(c(0,1),n),decreasing=TRUE),
                                            sort(rep(c(0,1),n))) %>% as.data.frame() 
names(dat) <- c("efficacy","safety","treatment","trt1","trt2")

dat_lab <- dat
dat_lab %<>% mutate(treatment=factor(treatment, labels=c("placebo","active")),
                   safety=factor(safety, labels=c("no AE","AE")))
```

The histograms of efficacy by treatment and AE status for the simulated data in the Figure confirm that the highest efficacy was observed for those in the active treatment group with an adverse event.

```{r br-b, cache=TRUE, fig.cap='Simulated data from Costa and Drury Benefit-Risk Example', fig.show = 'hold', fig.align='center', out.width='95%'}
ggplot(dat_lab, aes(x=efficacy, fill=treatment)) + 
  geom_histogram(bins=20, alpha=0.75) + facet_grid(treatment~safety)
```

Weakly informative normal priors were used for $\beta$ parameters and an inverse gamma with shape and scale parameters both equal to 0.001 was used for $\sigma$. For the copula parameter $\theta$, a flat uniform distribution on the interval [-1,1] was used. To explore the effect of fitting the joint copula model, each marginal model was also fit separately assuming independence between the outcomes. The R package `rstan`  was used to draw samples from the posterior distribution using the default No-U-Turn-Sampler (NUTS) MCMC algorithm, an implementation of Hamiltonian Monte Carlo. For each model, 4 chains with 1000 warmup iterations and 2000 sampling iterations were used resulting in 8000 samples from each posterior distribution. Diagnostics for the MCMC samples are shown in ...

```{r br-c, cache=TRUE}
## Stan code for B-R model
# http://mc-stan.org/rstan/
rstan_options(auto_write = TRUE)

# marginal models assuming independence
mod0a_code <- "
data {
  int N;
  matrix[N, 2] x;
  vector[N] y1;
}
parameters {
  // params for continuous (efficacy) outcome
   vector[2] beta1;
   real<lower=0> sigma;  
}
model {
  vector[N] mu;

  // priors
  beta1 ~ normal(0,1000);
  sigma ~ inv_gamma(0.001,0.001); 

  // marginal for continuous (efficacy) outcome
  mu = beta1[1]*x[,1] + beta1[2]*x[,2];
  y1 ~ normal(mu, sigma);
}
"

mod0b_code <- "
data {
  int N;
  matrix[N, 2] x;
  int<lower=0, upper=1> y2[N];
}
parameters {
  //params for binary (safety) outcome
   vector[2] beta2;
}
model {
  vector[N] p;

  // priors
  beta2 ~ normal(0,1000); 

  // marginal for binary (safety) outcome
  p = beta2[1]*x[,1] + beta2[2]*x[,2];
  y2 ~ bernoulli(Phi(p)); 
  }
generated quantities {
  vector[2] p;

  p[1] = Phi(beta2[1]);
  p[2] = Phi(beta2[2]);
}
"
```


```{r br-d, cache=TRUE}
# joint model w/o using cop function
mod_code <- "
data {
  int N;
  matrix[N, 2] x;
  vector[N] y1;
  int<lower=0, upper=1> y2[N];
}
parameters {
  // params for continuous (efficacy) outcome
  vector[2] beta1;
  vector<lower=0>[2] s;  

  //params for binary (safety) outcome
  vector[2] beta2;

  // copula dependence param
  vector<lower=-1, upper=1>[2] omega;  
}
model {
  vector[N] mu;
  vector[N] sigma;
  vector[N] p;
  vector[N] theta;

  // priors
  beta1 ~ normal(0,1000);
  beta2 ~ normal(0,1000); 
  s ~ inv_gamma(0.001,0.001); 

  // marginal for continuous (efficacy) outcome
  mu = beta1[1]*x[,1] + beta1[2]*x[,2];
  sigma = s[1]*x[,1] + s[2]*x[,2];

  // marginal for binary (safety) outcome
  p = Phi(beta2[1]*x[,1] + beta2[2]*x[,2]);

  // copula dependence parameter
  theta = omega[1]*x[,1]+omega[2]*x[,2];

  // build log-likelihood
  for(i in 1:N){
    target += normal_lpdf(y1[i]|mu[i],sigma[i]);
      if (y2[i]==0) {
        target += normal_lcdf((inv_Phi(1-p[i])-theta[i]*
inv_Phi(normal_cdf(y1[i],mu[i],sigma[i])))/sqrt(1-theta[i]^2)|0,1);
      } else {
        target += normal_lccdf((inv_Phi(1-p[i])-theta[i]*
inv_Phi(normal_cdf(y1[i],mu[i],sigma[i])))/sqrt(1-theta[i]^2)|0,1);
      }
    }

}
generated quantities {
  vector[2] mu;
  vector[2] p;
  vector[2] theta;
  vector[2] rho;

  mu[1] = beta1[1];
  mu[2] = beta1[2];

  p[1] = Phi(beta2[1]);
  p[2] = Phi(beta2[2]);

  theta[1] = omega[1];
  theta[2] = omega[2];

  rho[1] = theta[1]*exp(normal_lpdf(inv_Phi(p[1])|0,1))/sqrt(p[1]*(1-p[1]));
  rho[2] = theta[2]*exp(normal_lpdf(inv_Phi(p[2])|0,1))/sqrt(p[2]*(1-p[2]));
}
"
```

use coded log-likelihood function rather than hardcoding
```{r br-d2, cache=TRUE}
# joint model
mod_code2 <- "
functions {
  real binorm_cop_lp(real y1, real mu, real sigma, real y2, real p, real theta) {
    real targ = normal_lpdf(y1|mu,sigma);
      if (y2==0) {
        targ = targ + normal_lcdf((inv_Phi(1-p)-theta*
inv_Phi(normal_cdf(y1,mu,sigma)))/sqrt(1-theta^2)|0,1);
      } else {
        targ = targ + normal_lccdf((inv_Phi(1-p)-theta*
inv_Phi(normal_cdf(y1,mu,sigma)))/sqrt(1-theta^2)|0,1);
      }
  return targ;
  }
}
data {
  int N;
  matrix[N, 2] x;
  vector[N] y1;
  int<lower=0, upper=1> y2[N];
}
parameters {
  // params for continuous (efficacy) outcome
  vector[2] beta1;
  vector<lower=0>[2] s;  

  //params for binary (safety) outcome
  vector[2] beta2;

  // copula dependence param
  vector<lower=-1, upper=1>[2] omega;  
}
model {
  vector[N] mu;
  vector[N] sigma;
  vector[N] p;
  vector[N] theta;

  // priors
  beta1 ~ normal(0,1000);
  beta2 ~ normal(0,1000); 
  s ~ inv_gamma(0.001,0.001); 

  // marginal for continuous (efficacy) outcome
  mu = beta1[1]*x[,1] + beta1[2]*x[,2];
  sigma = s[1]*x[,1] + s[2]*x[,2];

  // marginal for binary (safety) outcome
  p = Phi(beta2[1]*x[,1] + beta2[2]*x[,2]);

  // copula dependence parameter
  theta = omega[1]*x[,1]+omega[2]*x[,2];

  // build log-likelihood
  for(i in 1:N){
    target += binorm_cop_lp(y1[i],mu[i],sigma[i], y2[i], p[i], theta[i]);
    }

}
generated quantities {
  vector[2] mu;
  vector[2] p;
  vector[2] theta;
  vector[2] rho;

  mu[1] = beta1[1];
  mu[2] = beta1[2];

  p[1] = Phi(beta2[1]);
  p[2] = Phi(beta2[2]);

  theta[1] = omega[1];
  theta[2] = omega[2];

  rho[1] = theta[1]*exp(normal_lpdf(inv_Phi(p[1])|0,1))/sqrt(p[1]*(1-p[1]));
  rho[2] = theta[2]*exp(normal_lpdf(inv_Phi(p[2])|0,1))/sqrt(p[2]*(1-p[2]));
}
"
```

```{r br-e, cache=TRUE, warning=FALSE, include=FALSE}
## Run Stan models
# MCMC parameters
options(mc.cores = parallel::detectCores())
n_chains <- 4
n_warmup <- 1000
n_iter <- 3000

## marginal models assuming independence
# format data into list for stan
mod0_data <- list(N=nrow(dat), x=dat[,c("trt1","trt2")], y1=dat$efficacy, y2=dat$safety)

# fit efficacy marginal model
fit0a <- stan(model_code = mod0a_code, data=mod0_data, 
              iter=n_iter, warmup=n_warmup, chains=n_chains)

# fit safety marginal model
fit0b <- stan(model_code = mod0b_code, data=mod0_data, 
              iter=n_iter, warmup=n_warmup, chains=n_chains)

## joint copula model
# efficacy marginal model MLE for initialization
mle1<-summary(lm(efficacy~trt1+trt2-1,data=dat))
 
# safety marginal model MLE for initialization
mle2<-glm(safety~trt1+trt2-1,data=dat,family=binomial(link="probit"))

# format data into list for stan
mod_data <- list(N=nrow(dat), x=dat[,c("trt1","trt2")], y1=dat$efficacy, y2=dat$safety)

#initalize margins at jittered MLE estimate
init_list <- rep(list(list(beta1=jitter(mle1$coefficients[,1],amount=5),
                       beta2=jitter(mle2$coefficients,amount=5),
                       s=jitter(rep(mle1$sigma,2),amount=5))), n_chains)

# fit joint model
br_fit <- stan(model_code = mod_code, data=mod_data, seed=3578935,
             iter=n_iter, chains=n_chains, warmup=n_warmup,
             init=init_list, control = list(adapt_delta = 0.95))
```

```{r br-e2, cache=TRUE, warning=FALSE, include=FALSE}
# fit joint model w/ binorm cop function
br_fit2 <- stan(model_code = mod_code2, data=mod_data, seed=3578935,
             iter=n_iter, chains=n_chains, warmup=n_warmup,
             init=init_list, control = list(adapt_delta = 0.95))
```


Table below summarizes the mean, Monte Carlo standard error, standard deviation, and quantiles of the posterior distributions for parameters $\mu_t$, $p_t$, $\rho_t$, and $\theta_t$ from the normal copula model. The number of effective samples -- a function of the correlation between sample draws -- along with Rhat -- a measure of MCMC convergence -- are also shown. The model performs reasonable well with posterior median estimates close to the true values for all parameters except the correlation between outcomes $\rho_1$ and adverse event rate $p_1$ in the placebo group.

```{r br-tab0, cache=TRUE}
br_tab <- round(summary(br_fit, pars=c("mu","p","rho","theta"))$summary,2) 
br_tab2 <- round(summary(br_fit2, pars=c("mu","p","rho","theta"))$summary,2) 
```

```{r br-tab, cache=TRUE, eval=knitr::is_latex_output(), echo=FALSE, results='asis'}
rownames(br_tab)<- c("$\\mu_1$","$\\mu_2$","$p_1$","$p_2$","$\\rho_1$","$\\rho_2$","$\\theta_1$","$\\theta_2$")
kable(br_tab, "latex", booktabs = TRUE, escape=FALSE, 
      caption = 'Benefit-Risk Copula Model Posterior Summary',
      col.names = c("Mean", "MCSE Mean", "SD", "$2.5\\%$", "$25\\%$",
                    "$50\\%$", "$75\\%$", "$97.5\\%$", "num. eff. samps", "Rhat")) 
```

```{r br-tab-html, cache=TRUE, eval=knitr::is_html_output(), echo=FALSE}
rownames(br_tab)<- c("$\\mu_1$","$\\mu_2$","$p_1$","$p_2$","$\\rho_1$","$\\rho_2$","$\\theta_1$","$\\theta_2$")
kable(br_tab, "html", booktabs = TRUE, escape=FALSE, 
      caption = 'Benefit-Risk Copula Model Posterior Summary',
      col.names = c("Mean", "MCSE Mean", "SD", "2.5\\%", "25\\%",
                    "50\\%", "75\\%", "97.5\\%", "eff. num. samps", "Rhat")) 
```

Using the posterior samples, the difference in mean efficacy response $\mu_2-\mu_1$ and the difference in probability of adverse events $p_2 - p_1$ was calculated for the normal copula and independence models. Figures `r if (knitr::is_html_output()) '\\@ref(fig:br-f-html)' else '\\@ref(fig:br-f)'` and `r if (knitr::is_html_output()) '\\@ref(fig:br-f-ind-html)' else '\\@ref(fig:br-f-ind)'` plot the results along with overlaid density curves and marginal histograms. The marginal histograms are nearly identical for both models, but the efficacy and safety treatment differences from the copula model have a clear positive dependence while there is no relationship between them in the independence model as expected. 

```{r br-f, cache=TRUE}
#calculate treatment effect (efficacy) and risk difference (safety)
posterior_mu <- extract(br_fit, pars=c("mu[1]","mu[2]"))
mu <- do.call(cbind.data.frame, posterior_mu) %>% mutate(mu_diff=`mu[2]`-`mu[1]`)

posterior_p <- extract(br_fit, pars=c("p[1]","p[2]"))
p <- do.call(cbind.data.frame, posterior_p) %>% mutate(p_diff=`p[2]`-`p[1]`)

diffs<-cbind(mu,p) 

# assuming independence model
posterior_mu0 <- extract(fit0a, pars=c("beta1[1]","beta1[2]"))
mu0 <- do.call(cbind.data.frame, posterior_mu0) %>% mutate(mu_diff=`beta1[2]`-`beta1[1]`)

posterior_p0 <- extract(fit0b, pars=c("p[1]","p[2]"))
p0 <- do.call(cbind.data.frame, posterior_p0) %>% mutate(p_diff=`p[2]`-`p[1]`)

diffs0<-cbind(mu0,p0) 

save(br_fit, br_tab, diffs, diffs0, file="br_mod_out.RData")
```

```{r br-g-html, cache=TRUE, eval=knitr::is_html_output(), fig.cap='Posterior treatment effect vs. safety risk difference posterior estimates from normal copula model'}
# scatterplot with histogram margins
mu_diff_hist <- plot_ly(x=diffs$mu_diff, type="histogram", nbinsx = 25,
                        color=I("steelblue"), showlegend=FALSE)

p_diff_hist <- plot_ly(y=diffs$p_diff,type="histogram", nbinsy = 25,
                       color=I("steelblue"),showlegend=FALSE)

scatterplt <- plot_ly(x=diffs$mu_diff,y=diffs$p_diff) %>%
    add_histogram2dcontour(showscale=FALSE, ncontours=10, contours = list(coloring='none'),
                           color=I("steelblue"), line=list(width=2,smoothing=1.1),
                           showlegend=FALSE) %>%
    add_markers(x = diffs$mu_diff, y = diffs$p_diff, color=I("black"),
                marker=list(size=3), alpha=.25,showlegend=FALSE) %>%
    layout(xaxis=list(title ="Treatment Difference (Efficacy)"), 
           yaxis=list(title = "Treatment Difference (Safety)"))  

plt_emp <- plotly_empty(type="scatter",mode="markers")
  
marg_plot<-subplot(mu_diff_hist, plt_emp, scatterplt, p_diff_hist,
 nrows = 2, heights = c(.2, .8), widths = c(.8,.2),
 shareX=TRUE, shareY=TRUE)

marg_plot
```

```{r br-g-ind-html, cache=TRUE, eval=knitr::is_html_output(), fig.cap='Posterior treatment effect vs. safety risk difference posterior estimates from independence model'}
# scatterplot with histogram margins 
mu_diff_hist0 <- plot_ly(x=diffs0$mu_diff, type="histogram", nbinsx = 25,
                        color=I("steelblue"), showlegend=FALSE)

p_diff_hist0 <- plot_ly(y=diffs0$p_diff, type="histogram", nbinsy = 25,
                       color=I("steelblue"),showlegend=FALSE)

scatterplt0 <- plot_ly(x=diffs0$mu_diff, y=diffs0$p_diff) %>%
    add_histogram2dcontour(showscale=FALSE, ncontours=10, contours = list(coloring='none'),
                           color=I("steelblue"), line=list(width=2,smoothing=1.1),
                           showlegend=FALSE) %>%
    add_markers(x = diffs0$mu_diff, y = diffs0$p_diff, color=I("black"),
                marker=list(size=3), alpha=.25,showlegend=FALSE) %>%
    layout(xaxis=list(title ="Treatment Difference (Efficacy)"), 
           yaxis=list(title = "Treatment Difference (Safety)"))  

marg_plot0 <- subplot(mu_diff_hist0, plt_emp, scatterplt0, p_diff_hist0,
 nrows = 2, heights = c(.2, .8), widths = c(.8,.2),
 shareX=TRUE, shareY=TRUE)

marg_plot0
```

```{r br-g, cache=TRUE, eval=knitr::is_latex_output(), echo=FALSE, fig.cap='Posterior treatment effect vs. safety risk difference posterior estimates from normal copula model', fig.show = 'hold', fig.align='center', out.width='85%'}
# scatterplot with histogram margins
pp <- ggplot(diffs,aes(x=mu_diff,y=p_diff)) + geom_point(alpha=0.15) + geom_density2d() + 
  xlab("Treatment Difference (Efficacy)") + ylab("Treatment Difference (Safety)")
 
ggMarginal(pp, type="histogram", fill = "white", 
           xparams = list(bins=25), yparams = list(bins=25))
```

```{r br-g-ind, cache=TRUE, eval=knitr::is_latex_output(), echo=FALSE, fig.cap='Posterior treatment effect vs. safety risk difference posterior estimates from independence model', fig.show = 'hold', fig.align='center', out.width='85%'}
pp0 <- ggplot(diffs0,aes(x=mu_diff,y=p_diff)) + geom_point(alpha=0.15) + geom_density2d()+ 
  xlab("Treatment Difference (Efficacy)") + ylab("Treatment Difference (Safety)")

ggMarginal(pp0, type="histogram", fill = "white", 
           xparams = list(bins=25), yparams = list(bins=25))
```
